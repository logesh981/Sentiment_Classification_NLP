{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# %pip show tensorflow\n",
    "# Modeling\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, TextClassificationPipeline\n",
    "\n",
    "# # Hugging Face Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "# # Model performance evaluation\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random,math\n",
    "TRAINING_DIR=\"propaganda_dataset_v2\"\n",
    "files=os.listdir(TRAINING_DIR)\n",
    "#since we have just two files we dont need loops\n",
    "traindf= pd.read_csv(os.path.join(TRAINING_DIR,files[0]),sep = '\\t')\n",
    "testdf= pd.read_csv(os.path.join(TRAINING_DIR,files[1]),sep = '\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text(sentences):\n",
    "    start_sent = sentences.replace(\"<BOS>\",\"\")\n",
    "    end_sent =start_sent.replace(\"<EOS>\",\"\")\n",
    "    return end_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf[\"tagged_in_context\"]=testdf[\"tagged_in_context\"].map(convert_text)\n",
    "traindf[\"tagged_in_context\"]=traindf[\"tagged_in_context\"].map(convert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tagged_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>No,  he  will not be confirmed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>This declassification effort  won’t make thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flag_waving</td>\n",
       "      <td>The Obama administration misled the  American ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>“It looks like we’re capturing the demise of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>Location: Westerville, Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>We support and appreciate  your business.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>International Atomic Energy Agency (IAEA) Dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>What has been done: there has been work on for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>not_propaganda</td>\n",
       "      <td>This is  the law of gradualness not the gradua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>name_calling,labeling</td>\n",
       "      <td>In it, Jews are described as: “arrogant,” “jea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2414 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label                                  tagged_in_context\n",
       "0            not_propaganda                   No,  he  will not be confirmed. \n",
       "1            not_propaganda  This declassification effort  won’t make thing...\n",
       "2               flag_waving  The Obama administration misled the  American ...\n",
       "3            not_propaganda  “It looks like we’re capturing the demise of t...\n",
       "4            not_propaganda                      Location: Westerville, Ohio  \n",
       "...                     ...                                                ...\n",
       "2409         not_propaganda        We support and appreciate  your business.” \n",
       "2410         not_propaganda  International Atomic Energy Agency (IAEA) Dire...\n",
       "2411         not_propaganda  What has been done: there has been work on for...\n",
       "2412         not_propaganda  This is  the law of gradualness not the gradua...\n",
       "2413  name_calling,labeling  In it, Jews are described as: “arrogant,” “jea...\n",
       "\n",
       "[2414 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_class_traindf=traindf\n",
    "two_class_testdf=testdf\n",
    "\n",
    "two_class_traindf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tagged_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No,  he  will not be confirmed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This declassification effort  won’t make thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The Obama administration misled the  American ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>“It looks like we’re capturing the demise of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Location: Westerville, Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>1</td>\n",
       "      <td>We support and appreciate  your business.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>1</td>\n",
       "      <td>International Atomic Energy Agency (IAEA) Dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>1</td>\n",
       "      <td>What has been done: there has been work on for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>1</td>\n",
       "      <td>This is  the law of gradualness not the gradua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>0</td>\n",
       "      <td>In it, Jews are described as: “arrogant,” “jea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2414 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                  tagged_in_context\n",
       "0         1                   No,  he  will not be confirmed. \n",
       "1         1  This declassification effort  won’t make thing...\n",
       "2         0  The Obama administration misled the  American ...\n",
       "3         1  “It looks like we’re capturing the demise of t...\n",
       "4         1                      Location: Westerville, Ohio  \n",
       "...     ...                                                ...\n",
       "2409      1        We support and appreciate  your business.” \n",
       "2410      1  International Atomic Energy Agency (IAEA) Dire...\n",
       "2411      1  What has been done: there has been work on for...\n",
       "2412      1  This is  the law of gradualness not the gradua...\n",
       "2413      0  In it, Jews are described as: “arrogant,” “jea...\n",
       "\n",
       "[2414 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_labels(label):\n",
    "    return 1 if label==\"not_propaganda\" else 0\n",
    "two_class_testdf[\"label\"]= two_class_testdf[\"label\"].map(convert_labels)\n",
    "two_class_traindf[\"label\"]=two_class_traindf[\"label\"].map(convert_labels)\n",
    "two_class_traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_train_data = Dataset.from_pandas(two_class_traindf)\n",
    "hg_test_data = Dataset.from_pandas(two_class_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [1, 1, 0],\n",
       " 'tagged_in_context': ['No,  he  will not be confirmed. ',\n",
       "  'This declassification effort  won’t make things any worse than they are for President Trump.  ',\n",
       "  'The Obama administration misled the  American people  and Congress because they were desperate to get a deal with Iran, said Sen. ']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_train_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd7951c619646e18113958309d02f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2414 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d94273f57642d9bb9a43676dc68e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_data(data):\n",
    "    return tokenizer(data[\"tagged_in_context\"],\n",
    "                     max_length=140,\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\")\n",
    "# Tokenize the dataset\n",
    "dataset_train = hg_train_data.map(tokenize_data)\n",
    "dataset_test = hg_test_data.map(tokenize_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_transfer_learning_transformer/\",          \n",
    "    logging_dir='./sentiment_transfer_learning_transformer/logs',            \n",
    "    logging_strategy='epoch',\n",
    "    logging_steps=100,    \n",
    "    num_train_epochs=5,              \n",
    "    per_device_train_batch_size=10,  \n",
    "    per_device_eval_batch_size=10,  \n",
    "    learning_rate=5e-6,\n",
    "    seed=42,\n",
    "    save_strategy='epoch',\n",
    "    save_steps=100,\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 158 evaluation models in Hugging Face.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lvwerra/test',\n",
       " 'precision',\n",
       " 'code_eval',\n",
       " 'roc_auc',\n",
       " 'cuad',\n",
       " 'xnli',\n",
       " 'rouge',\n",
       " 'pearsonr',\n",
       " 'mse',\n",
       " 'super_glue',\n",
       " 'comet',\n",
       " 'cer',\n",
       " 'sacrebleu',\n",
       " 'mahalanobis',\n",
       " 'wer',\n",
       " 'competition_math',\n",
       " 'f1',\n",
       " 'recall',\n",
       " 'coval',\n",
       " 'mauve',\n",
       " 'xtreme_s',\n",
       " 'bleurt',\n",
       " 'ter',\n",
       " 'accuracy',\n",
       " 'exact_match',\n",
       " 'indic_glue',\n",
       " 'spearmanr',\n",
       " 'mae',\n",
       " 'squad',\n",
       " 'chrf',\n",
       " 'glue',\n",
       " 'perplexity',\n",
       " 'mean_iou',\n",
       " 'squad_v2',\n",
       " 'meteor',\n",
       " 'bleu',\n",
       " 'wiki_split',\n",
       " 'sari',\n",
       " 'frugalscore',\n",
       " 'google_bleu',\n",
       " 'bertscore',\n",
       " 'matthews_correlation',\n",
       " 'seqeval',\n",
       " 'trec_eval',\n",
       " 'rl_reliability',\n",
       " 'jordyvl/ece',\n",
       " 'angelina-wang/directional_bias_amplification',\n",
       " 'cpllab/syntaxgym',\n",
       " 'lvwerra/bary_score',\n",
       " 'kaggle/amex',\n",
       " 'kaggle/ai4code',\n",
       " 'hack/test_metric',\n",
       " 'yzha/ctc_eval',\n",
       " 'codeparrot/apps_metric',\n",
       " 'mfumanelli/geometric_mean',\n",
       " 'daiyizheng/valid',\n",
       " 'poseval',\n",
       " 'erntkn/dice_coefficient',\n",
       " 'mgfrantz/roc_auc_macro',\n",
       " 'Vlasta/pr_auc',\n",
       " 'gorkaartola/metric_for_tp_fp_samples',\n",
       " 'idsedykh/metric',\n",
       " 'idsedykh/codebleu2',\n",
       " 'idsedykh/codebleu',\n",
       " 'idsedykh/megaglue',\n",
       " 'cakiki/ndcg',\n",
       " 'brier_score',\n",
       " 'Vertaix/vendiscore',\n",
       " 'GMFTBY/dailydialogevaluate',\n",
       " 'GMFTBY/dailydialog_evaluate',\n",
       " 'jzm-mailchimp/joshs_second_test_metric',\n",
       " 'ola13/precision_at_k',\n",
       " 'yulong-me/yl_metric',\n",
       " 'abidlabs/mean_iou',\n",
       " 'abidlabs/mean_iou2',\n",
       " 'KevinSpaghetti/accuracyk',\n",
       " 'NimaBoscarino/weat',\n",
       " 'ronaldahmed/nwentfaithfulness',\n",
       " 'Viona/infolm',\n",
       " 'kyokote/my_metric2',\n",
       " 'kashif/mape',\n",
       " 'Ochiroo/rouge_mn',\n",
       " 'giulio98/code_eval_outputs',\n",
       " 'leslyarun/fbeta_score',\n",
       " 'giulio98/codebleu',\n",
       " 'anz2/iliauniiccocrevaluation',\n",
       " 'zbeloki/m2',\n",
       " 'xu1998hz/sescore',\n",
       " 'mase',\n",
       " 'mape',\n",
       " 'smape',\n",
       " 'dvitel/codebleu',\n",
       " 'NCSOFT/harim_plus',\n",
       " 'JP-SystemsX/nDCG',\n",
       " 'sportlosos/sescore',\n",
       " 'Drunper/metrica_tesi',\n",
       " 'jpxkqx/peak_signal_to_noise_ratio',\n",
       " 'jpxkqx/signal_to_reconstrution_error',\n",
       " 'hpi-dhc/FairEval',\n",
       " 'nist_mt',\n",
       " 'lvwerra/accuracy_score',\n",
       " 'character',\n",
       " 'charcut_mt',\n",
       " 'ybelkada/cocoevaluate',\n",
       " 'harshhpareek/bertscore',\n",
       " 'posicube/mean_reciprocal_rank',\n",
       " 'bstrai/classification_report',\n",
       " 'omidf/squad_precision_recall',\n",
       " 'Josh98/nl2bash_m',\n",
       " 'BucketHeadP65/confusion_matrix',\n",
       " 'BucketHeadP65/roc_curve',\n",
       " 'yonting/average_precision_score',\n",
       " 'transZ/test_parascore',\n",
       " 'transZ/sbert_cosine',\n",
       " 'hynky/sklearn_proxy',\n",
       " 'xu1998hz/sescore_english_mt',\n",
       " 'xu1998hz/sescore_german_mt',\n",
       " 'xu1998hz/sescore_english_coco',\n",
       " 'xu1998hz/sescore_english_webnlg',\n",
       " 'unnati/kendall_tau_distance',\n",
       " 'r_squared',\n",
       " 'Viona/fuzzy_reordering',\n",
       " 'Viona/kendall_tau',\n",
       " 'lhy/hamming_loss',\n",
       " 'lhy/ranking_loss',\n",
       " 'Muennighoff/code_eval',\n",
       " 'yuyijiong/quad_match_score',\n",
       " 'Splend1dchan/cosine_similarity',\n",
       " 'Yeshwant123/mcc',\n",
       " 'transformersegmentation/segmentation_scores',\n",
       " 'sma2023/wil',\n",
       " 'chanelcolgate/average_precision',\n",
       " 'tempcaeriose/wil',\n",
       " '7neccuitku/sescore',\n",
       " 'ckb/unigram',\n",
       " 'Felipehonorato/eer',\n",
       " 'manueldeprada/beer',\n",
       " 'tialaeMceryu/unigram',\n",
       " 'cottisanga/wil',\n",
       " 'mcnemar',\n",
       " 'exact_match',\n",
       " 'wilcoxon',\n",
       " 'ncoop57/levenshtein_distance',\n",
       " 'kaleidophon/almost_stochastic_order',\n",
       " 'word_length',\n",
       " 'lvwerra/element_count',\n",
       " 'word_count',\n",
       " 'text_duplicates',\n",
       " 'perplexity',\n",
       " 'label_distribution',\n",
       " 'toxicity',\n",
       " 'prb977/cooccurrence_count',\n",
       " 'regard',\n",
       " 'honest',\n",
       " 'NimaBoscarino/pseudo_perplexity',\n",
       " 'ybelkada/toxicity',\n",
       " 'ronaldahmed/ccl_win',\n",
       " 'meg/perplexity']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of evaluation modules\n",
    "print(f'There are {len(evaluate.list_evaluation_modules())} evaluation models in Hugging Face.\\n')\n",
    "\n",
    "# List all evaluation metrics\n",
    "evaluate.list_evaluation_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the metric\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_pred\n",
    "    # probabilities = tf.nn.softmax(logits)\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tagged_in_context. If tagged_in_context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\lv228\\AppData\\Local\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2414\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1210\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78464eb2ce64343b14ff145c913712a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e06a658b2340fe98657985ed58a017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_test_predict = trainer.predict(dataset_test)\n",
    "\n",
    "y_test_logits = y_test_predict.predictions\n",
    "\n",
    "# First 5 predicted probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.00254825, 0.9974517 ],\n",
       "       [0.96868247, 0.0313175 ],\n",
       "       [0.9934496 , 0.00655044],\n",
       "       [0.00200245, 0.99799746],\n",
       "       [0.9967861 , 0.00321387]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_probabilities = tf.nn.softmax(y_test_logits)\n",
    "y_test_probabilities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_labels = np.argmax(y_test_probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_actual_labels = y_test_predict.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_actual_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edec202124714f5f9c2a73df08c1a610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2690449953079224,\n",
       " 'eval_accuracy': 0.7517241379310344,\n",
       " 'eval_runtime': 22.4253,\n",
       " 'eval_samples_per_second': 25.864,\n",
       " 'eval_steps_per_second': 25.864,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7575757575757576}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load f1 metric\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "# Compute f1 metric\n",
    "metric_f1.compute(predictions=y_test_pred_labels, references=y_test_actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer_to_our_system\n",
    "tokenizer.save_pretrained('./sentiment_transfer_learning_transformer/')\n",
    "\n",
    "# Save model to out system\n",
    "trainer.save_model('./sentiment_transfer_learning_transformer/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
